{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow attempt on HeatReplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from tensorflow.contrib import learn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from context import *\n",
    "from util.dfmgmt import initSet, wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = initSet()\n",
    "df = df[df['decade'] != 2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>decade</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>density</th>\n",
       "      <th>unique_words_raw</th>\n",
       "      <th>density_raw</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>syllables</th>\n",
       "      <th>most_used_freq</th>\n",
       "      <th>explicit</th>\n",
       "      <th>total_curses</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>charted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1961</td>\n",
       "      <td>1960</td>\n",
       "      <td>36</td>\n",
       "      <td>72</td>\n",
       "      <td>65</td>\n",
       "      <td>158</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.367848</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1961</td>\n",
       "      <td>1960</td>\n",
       "      <td>45</td>\n",
       "      <td>91</td>\n",
       "      <td>74</td>\n",
       "      <td>197</td>\n",
       "      <td>45</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.771777</td>\n",
       "      <td>0.9712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1961</td>\n",
       "      <td>1960</td>\n",
       "      <td>54</td>\n",
       "      <td>103</td>\n",
       "      <td>88</td>\n",
       "      <td>223</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>17</td>\n",
       "      <td>98</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.885650</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1961</td>\n",
       "      <td>1960</td>\n",
       "      <td>42</td>\n",
       "      <td>148</td>\n",
       "      <td>66</td>\n",
       "      <td>263</td>\n",
       "      <td>81</td>\n",
       "      <td>61</td>\n",
       "      <td>36</td>\n",
       "      <td>76</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.889886</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1961</td>\n",
       "      <td>1960</td>\n",
       "      <td>28</td>\n",
       "      <td>131</td>\n",
       "      <td>60</td>\n",
       "      <td>354</td>\n",
       "      <td>56</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.940000</td>\n",
       "      <td>0.9812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  decade  unique_words  density  unique_words_raw  density_raw  nouns  \\\n",
       "0  1961    1960            36       72                65          158     34   \n",
       "1  1961    1960            45       91                74          197     45   \n",
       "2  1961    1960            54      103                88          223     45   \n",
       "3  1961    1960            42      148                66          263     81   \n",
       "4  1961    1960            28      131                60          354     56   \n",
       "\n",
       "   verbs  adjectives  syllables  most_used_freq  explicit  total_curses  \\\n",
       "0     30          10         70               7         0             0   \n",
       "1     37          19         81               6         0             0   \n",
       "2     48          17         98              10         0             0   \n",
       "3     61          36         76              24         0             0   \n",
       "4     77           5         57              38         0             0   \n",
       "\n",
       "   reading_score  sentiment  charted  \n",
       "0       2.367848     0.9901        0  \n",
       "1       2.771777     0.9712        1  \n",
       "2       3.885650     0.9974        1  \n",
       "3       2.889886     0.9993        1  \n",
       "4       2.940000     0.9812        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop both year and decade\n",
    "dropList = ['most_used_term']\n",
    "removeList = ['decade', 'year', 'charted']\n",
    "target = 'charted'  # main feature to be predicted\n",
    "df, features = wrangle(df, dropList, removeList, True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df[features].as_matrix()\n",
    "y = df[target].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Do cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gridSearchTF(X_train, X_test, y_train, y_test, units, steps=200, batch_size=64):\n",
    "\n",
    "    units = units.split(',')\n",
    "    # Instantiate model\n",
    "    clf = learn.DNNClassifier(hidden_units=units, n_classes=len(units))\n",
    "\n",
    "    # Train model\n",
    "    clf.fit(X_train, y_train, steps=steps, batch_size=batch_size)\n",
    "\n",
    "    # Score model\n",
    "    score = metrics.accuracy_score(y_test, clf.predict(X_test))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import sample, shuffle\n",
    "\n",
    "def randomList(nClasses):\n",
    "    \n",
    "    new = ''\n",
    "    \n",
    "    for i in xrange(nClasses):        \n",
    "        new += str(sample(xrange(30, 101), 10)[0]) + ','\n",
    "\n",
    "    return new[:-1]\n",
    "\n",
    "def randomizer(nClasses, nSearches):\n",
    "\n",
    "    hiddenUnits = []\n",
    "\n",
    "    for _ in xrange(nSearches):\n",
    "        hiddenUnits.append(randomList(nClasses))\n",
    "        \n",
    "    shuffle(hiddenUnits)\n",
    "\n",
    "    return hiddenUnits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:38<00:00,  9.82s/it]\n"
     ]
    }
   ],
   "source": [
    "params = {units: None for units in randomizer(3, 10)}\n",
    "\n",
    "for units in tqdm(params):\n",
    "    params[units] = gridSearchTF(X_train, X_test, y_train, y_test, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'48,63,95': 0.67796610169491522,\n",
       " '53,80,36': 0.68318122555410687,\n",
       " '54,77,97': 0.67535853976531945,\n",
       " '71,65,96': 0.6805736636245111,\n",
       " '75,49,37': 0.69361147327249018,\n",
       " '81,76,39': 0.67275097783572357,\n",
       " '85,65,66': 0.68839634941329853,\n",
       " '91,33,35': 0.67535853976531945,\n",
       " '92,63,30': 0.69621903520208606,\n",
       " '99,83,43': 0.68448500651890487}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
